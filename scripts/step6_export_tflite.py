import tensorflow as tf
import numpy as np
import os
import sys
import traceback
import logging

from step3_model import build_ctc_transformer_model
from step2_dataset import load_char2idx
from step4_train import CTCModel

def export_tflite():
    try:
        # Táº¯t cáº£nh bÃ¡o log
        tf.get_logger().setLevel(logging.ERROR)
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

        print("ğŸ”§ Báº¯t Ä‘áº§u export mÃ´ hÃ¬nh sang TensorFlow Lite...")

        # Load vocab
        print("ğŸ“š Load vocabulary...")
        char2idx = load_char2idx()
        vocab_size = len(char2idx)
        print(f"âœ… Vocabulary size: {vocab_size}")

        # Build mÃ´ hÃ¬nh vÃ  load weights
        print("ğŸ§  Khá»Ÿi táº¡o mÃ´ hÃ¬nh...")
        base_model = build_ctc_transformer_model(
            input_dim=128,
            vocab_size=vocab_size,
            d_model=128,
            num_heads=4,
            num_layers=4,
            ff_dim=256,
        )
        model = CTCModel(base_model)

        # Khá»Ÿi táº¡o dummy input vá»›i shape cá»‘ Ä‘á»‹nh 112 frame
        dummy_input = tf.ones((1, 112, 128), dtype=tf.float32)
        _ = model(dummy_input, training=False)

        # Load weights
        model_path = "checkpoints/best_model.weights.h5"
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file weights: {model_path}")
        model.load_weights(model_path)
        print(f"âœ… ÄÃ£ load weights tá»«: {model_path}")

        # Táº¡o hÃ m concrete function vá»›i input shape cá»‘ Ä‘á»‹nh
        print("ğŸ”¨ Táº¡o concrete function Ä‘á»ƒ export...")
        @tf.function(input_signature=[tf.TensorSpec(shape=[1, 112, 128], dtype=tf.float32)])
        def inference_fn(inputs):
            logits = base_model(inputs, training=False)
            return logits  # Chá»‰ tráº£ vá» logits thÃ´, khÃ´ng decode

        concrete_func = inference_fn.get_concrete_function()

        # Convert sang TFLite
        print("ğŸ”„ Äang chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng .tflite...")
        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
        #converter.optimizations = [tf.lite.Optimize.DEFAULT]
        #converter._experimental_lower_tensor_list_ops = True
        converter.experimental_enable_resource_variables = False

        tflite_model = converter.convert()
        print("âœ… Chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng!")

        # LÆ°u model ra file
        os.makedirs("tflite_model", exist_ok=True)
        tflite_path = "tflite_model/model.tflite"
        with open(tflite_path, "wb") as f:
            f.write(tflite_model)
        print(f"ğŸ’¾ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {tflite_path}")

        # Kiá»ƒm tra láº¡i model TFLite
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        print("ğŸ” Kiá»ƒm tra mÃ´ hÃ¬nh TFLite thÃ nh cÃ´ng.")

    except Exception:
        print("âŒ Gáº·p lá»—i trong quÃ¡ trÃ¬nh export:")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    export_tflite()
