import tensorflow as tf
import numpy as np
import librosa
import sys
import os
import traceback
import re

from step2_dataset import load_char2idx  # H√†m load char2idx.npy chu·∫©n t·ª´ th∆∞ m·ª•c

def load_audio_mfcc(file_path, sample_rate=16000, n_mfcc=128, fixed_length=1000):
    """
    Load file audio, chuy·ªÉn sang MFCC shape (1, fixed_length, n_mfcc).
    N·∫øu MFCC qu√° d√†i th√¨ c·∫Øt, qu√° ng·∫Øn th√¨ padding 0.
    """
    audio, sr = librosa.load(file_path, sr=sample_rate)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc).T  # (T, n_mfcc)
    if mfcc.shape[0] > fixed_length:
        mfcc = mfcc[:fixed_length, :]
    else:
        pad_width = fixed_length - mfcc.shape[0]
        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')
    mfcc = mfcc.astype(np.float32)
    mfcc = np.expand_dims(mfcc, axis=0)  # (1, fixed_length, n_mfcc)
    return mfcc

def ctc_greedy_decode(logits, blank_index=0):
    """
    Gi·∫£i m√£ logits b·∫±ng greedy CTC decode:
    - Ch·ªçn max m·ªói step
    - B·ªè blank (index blank_index)
    - Collapse k√Ω t·ª± l·∫∑p li√™n ti·∫øp
    """
    pred_ids = np.argmax(logits[0], axis=-1)  # logits shape: (1, time_steps, vocab_size)
    deduped = []
    prev = blank_index
    for idx in pred_ids:
        if idx != prev and idx != blank_index:
            deduped.append(idx)
        prev = idx
    return deduped  # Tr·∫£ v·ªÅ danh s√°ch index k√Ω t·ª± (kh√¥ng c√≥ blank v√† k√Ω t·ª± l·∫∑p)

def decode_to_text(decoded_ids, idx2char):
    """
    Chuy·ªÉn danh s√°ch index sang text:
    - Thay k√Ω t·ª± ƒë·∫∑c bi·ªát th√†nh space n·∫øu c·∫ßn
    - Lo·∫°i b·ªè blank (n·∫øu c√≤n s√≥t)
    - Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    """
    chars = []
    for i in decoded_ids:
        ch = idx2char.get(i, '')
        if ch == '<blank>':
            continue
        if ch in ['_', ' ', 'SPACE']:
            ch = ' '
        chars.append(ch)
    text = ''.join(chars)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def run_inference(tflite_model_path, wav_path):
    try:
        print("üîç Load m√¥ h√¨nh TFLite...")
        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)
        interpreter.allocate_tensors()

        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        print(f"üì• Input tensor shape: {input_details[0]['shape']}")
        print(f"üì§ Output tensor shape: {output_details[0]['shape']}")

        print("üéß Ti·ªÅn x·ª≠ l√Ω file √¢m thanh th√†nh MFCC...")
        mfcc = load_audio_mfcc(wav_path, n_mfcc=input_details[0]['shape'][2], fixed_length=input_details[0]['shape'][1])
        print(f"MFCC shape sau ti·ªÅn x·ª≠ l√Ω: {mfcc.shape}")

        # ƒê·∫£m b·∫£o MFCC ƒë√∫ng shape v·ªõi input model
        expected_shape = input_details[0]['shape']
        if mfcc.shape != tuple(expected_shape):
            print(f"‚ö†Ô∏è Warning: MFCC shape {mfcc.shape} kh√¥ng kh·ªõp input model {expected_shape}, ƒëi·ªÅu ch·ªânh l·∫°i...")
            current_len = mfcc.shape[1]
            target_len = expected_shape[1]
            if current_len > target_len:
                mfcc = mfcc[:, :target_len, :]
            else:
                pad_len = target_len - current_len
                mfcc = np.pad(mfcc, ((0,0),(0,pad_len),(0,0)), mode='constant')
            print(f"MFCC shape sau ƒëi·ªÅu ch·ªânh: {mfcc.shape}")

        interpreter.set_tensor(input_details[0]['index'], mfcc)
        interpreter.invoke()

        logits = interpreter.get_tensor(output_details[0]['index'])  # shape (1, time_steps, vocab_size)
        print(f"Logits shape: {logits.shape}")

        # Load b·∫£ng char2idx v√† t·∫°o idx2char
        char2idx = load_char2idx()
        idx2char = {v: k for k, v in char2idx.items()}
        blank_index = char2idx.get('<blank>', 0)

        print("üî§ B·∫£ng idx2char sample (first 20 chars):")
        for i in range(min(20, len(idx2char))):
            print(f"  {i}: '{idx2char.get(i, '')}'")
        print(f"Blank index: {blank_index}")

        decoded_ids = ctc_greedy_decode(logits, blank_index=blank_index)
        decoded_text = decode_to_text(decoded_ids, idx2char)

        print("üìù K·∫øt qu·∫£ nh·∫≠n di·ªán vƒÉn b·∫£n:")
        print(decoded_text if decoded_text else "(Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c vƒÉn b·∫£n)")

    except Exception:
        print("‚ùå L·ªói khi ch·∫°y inference:")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("C√°ch d√πng: python step7_inference.py <tflite_model_path> <wav_path>")
        sys.exit(1)

    tflite_model_path = sys.argv[1]
    wav_path = sys.argv[2]

    if not os.path.exists(tflite_model_path):
        print(f"‚ùå File m√¥ h√¨nh kh√¥ng t·ªìn t·∫°i: {tflite_model_path}")
        sys.exit(1)
    if not os.path.exists(wav_path):
        print(f"‚ùå File √¢m thanh kh√¥ng t·ªìn t·∫°i: {wav_path}")
        sys.exit(1)

    run_inference(tflite_model_path, wav_path)
